{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f406ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# suppress irrelevant pandas warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy connectable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de7ba150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.connect()\n",
    "    \n",
    "    def connect(self):\n",
    "        try:\n",
    "            self.connection = psycopg2.connect(\n",
    "                host=self.config.host,\n",
    "                database=self.config.database,\n",
    "                user=self.config.user,\n",
    "                password=self.config.password,\n",
    "                port=self.config.port\n",
    "            )\n",
    "            print(\"Connection to RDS successful\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to RDS: {e}\")\n",
    "            \n",
    "    def data(self, query, limit=100, offset=0):\n",
    "        df = None\n",
    "        try:\n",
    "            query = f\"SELECT * FROM ({query}) LIMIT {limit} OFFSET {offset}\"\n",
    "            df = pd.read_sql(query, self.connection)\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying data: {e}\")\n",
    "        return df\n",
    "    \n",
    "    def count(self, query):\n",
    "        total_count = None\n",
    "        try:\n",
    "            count_query = f\"SELECT COUNT(*) FROM ({query}) AS count_query\"\n",
    "            result = pd.read_sql(count_query, self.connection)\n",
    "            total_count = result.iloc[0, 0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying count: {e}\")\n",
    "        return total_count\n",
    "\n",
    "    def enrollment_query(self):\n",
    "        query = \"\"\"\n",
    "        SELECT e.EnrollmentID, e.PersonalID, e.ProjectId, e.EntryDate, e.DateOfEngagement,\n",
    "            CASE \n",
    "                WHEN e.LivingSituation = 116 THEN 'Place Not Meant For Habitation'\n",
    "                WHEN e.LivingSituation = 101 THEN 'Emergency Shelter'\n",
    "                WHEN e.LivingSituation = 118 THEN 'Safe Haven'\n",
    "                WHEN e.LivingSituation = 215 THEN 'Foster Care Home'\n",
    "                WHEN e.LivingSituation = 206 THEN 'Hospital/ Medical Facility'\n",
    "                WHEN e.LivingSituation = 207 THEN 'Jail'\n",
    "                WHEN e.LivingSituation = 225 THEN 'Long-term care facility'\n",
    "                WHEN e.LivingSituation = 204 THEN 'Psychiatric hospital'\n",
    "                WHEN e.LivingSituation = 205 THEN 'Substance abuse treatment facility'\n",
    "                WHEN e.LivingSituation = 302 THEN 'Transitional Housing'\n",
    "                WHEN e.LivingSituation = 329 THEN 'Halfway House'\n",
    "                WHEN e.LivingSituation = 314 THEN 'Hotel/ Motel'\n",
    "                WHEN e.LivingSituation = 332 THEN 'Host Home'\n",
    "                WHEN e.LivingSituation = 312 THEN 'Staying or living with family, temporary tenure'\n",
    "                WHEN e.LivingSituation = 313 THEN 'Staying or living with friends, temporary tenure'\n",
    "                WHEN e.LivingSituation = 327 THEN 'HOPWA funded project TH'\n",
    "                WHEN e.LivingSituation = 336 THEN 'Staying/ living in friends house'\n",
    "                WHEN e.LivingSituation = 335 THEN 'Staying/ living in families house'\n",
    "                WHEN e.LivingSituation = 422 THEN 'Staying or living with family, permanent tenure'\n",
    "                WHEN e.LivingSituation = 423 THEN 'Staying or living with friends, permanent tenure'\n",
    "                WHEN e.LivingSituation = 426 THEN 'HOPWA funded project PH'\n",
    "                WHEN e.LivingSituation = 410 THEN 'Rental by client, no subsidy'\n",
    "                WHEN e.LivingSituation = 435 THEN 'Rental by client, with subsidy'\n",
    "                WHEN e.LivingSituation = 421 THEN 'Owned by client, no subsidy'\n",
    "                WHEN e.LivingSituation = 411 THEN 'Owned by client, with subsidy'\n",
    "                WHEN e.LivingSituation = 30  THEN 'No exit interview completed'\n",
    "                WHEN e.LivingSituation = 17  THEN 'Other'\n",
    "                WHEN e.LivingSituation = 24  THEN 'Deceased'\n",
    "                WHEN e.LivingSituation = 37  THEN 'Unable to determine'\n",
    "                WHEN e.LivingSituation = 8   THEN 'Client doesn''t know'\n",
    "                WHEN e.LivingSituation = 9   THEN 'Client prefers not to answer'\n",
    "                WHEN e.LivingSituation = 99  THEN 'Data Not Collected'\n",
    "                WHEN e.LivingSituation IS NULL THEN 'Data Not Collected'\n",
    "                ELSE 'Unknown'\n",
    "            END AS LivingSituation,\n",
    "            CASE\n",
    "                WHEN e.LivingSituation >= 100 AND e.LivingSituation < 200 THEN 'Homeless Situation'\n",
    "                WHEN e.LivingSituation >= 200 AND e.LivingSituation < 300 THEN 'Institutional Situation'\n",
    "                WHEN e.LivingSituation >= 300 AND e.LivingSituation < 400 THEN 'Temporary Situation'\n",
    "                WHEN e.LivingSituation >= 400 AND e.LivingSituation < 500 THEN 'Permanent Housing Situation'\n",
    "                ELSE 'Other'\n",
    "            END AS LivingSituationGrouping,\n",
    "            x.ExitID, x.ExitDate,\n",
    "            CASE\n",
    "                WHEN x.Destination IS NULL THEN 99\n",
    "                ELSE x.Destination\n",
    "            END AS Destination,\n",
    "            CASE\n",
    "                WHEN x.Destination >= 100 AND x.Destination < 200 THEN 'Homeless Situation'\n",
    "                WHEN x.Destination >= 200 AND x.Destination < 300 THEN 'Institutional Situation'\n",
    "                WHEN x.Destination >= 300 AND x.Destination < 400 THEN 'Temporary Situation'\n",
    "                WHEN x.Destination >= 400 AND x.Destination < 500 THEN 'Permanent Housing Situation'\n",
    "                ELSE 'Other'\n",
    "            END AS DestinationGrouping\n",
    "        FROM Enrollment e\n",
    "        INNER JOIN Exit x\n",
    "            ON e.EnrollmentID = x.EnrollmentID\n",
    "        \"\"\"\n",
    "        return query\n",
    "    \n",
    "    def log_experiment(\n",
    "        self,\n",
    "        model_type: str,\n",
    "        hyperparameters: dict,\n",
    "        training_data_version: str,\n",
    "        performance_metrics: dict,\n",
    "        s3_model_location: str,\n",
    "        start_time: datetime,\n",
    "        end_time: datetime,\n",
    "        status: str,\n",
    "        notes: str\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Logs an experiment to the PostgreSQL database.\n",
    "\n",
    "        Parameters:\n",
    "        - model_type (str): The type of the model (e.g., 'RandomForest', 'GBM').\n",
    "        - hyperparameters (dict): A dictionary of hyperparameters used for the model.\n",
    "        - training_data_version (str): The version of the training data.\n",
    "        - performance_metrics (dict): A dictionary of performance metrics (e.g., accuracy, F1 score).\n",
    "        - s3_model_location (str): The S3 location where the model weights are stored.\n",
    "        - start_time (datetime): The start time of the experiment.\n",
    "        - end_time (datetime): The end time of the experiment.\n",
    "        - status (str): The status of the experiment (e.g., 'Completed', 'Failed').\n",
    "        - notes (str): Any additional notes for the experiment.\n",
    "\n",
    "        Returns:\n",
    "        - None: Logs the experiment in the database.\n",
    "        \"\"\"\n",
    "        cursor = self.connection.cursor()\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO experiments (\n",
    "                model_type, \n",
    "                hyperparameters, \n",
    "                training_data_version, \n",
    "                performance_metrics, \n",
    "                s3_model_location, \n",
    "                start_time, \n",
    "                end_time, \n",
    "                status, \n",
    "                notes\n",
    "            ) \n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the insert query\n",
    "        cursor.execute(insert_query, (\n",
    "            model_type, \n",
    "            json.dumps(hyperparameters), \n",
    "            training_data_version, \n",
    "            json.dumps(performance_metrics), \n",
    "            s3_model_location, \n",
    "            start_time, \n",
    "            end_time, \n",
    "            status, \n",
    "            notes\n",
    "        ))\n",
    "\n",
    "        self.connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "931a919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRetriever:\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "        \n",
    "    def records(self):\n",
    "        query = self.data_source.enrollment_query()\n",
    "        total_count = self.data_source.count(query)\n",
    "\n",
    "        if total_count is None:\n",
    "            print(\"Failed to retrieve total count.\")\n",
    "            return None\n",
    "\n",
    "        all_data = pd.DataFrame()\n",
    "        batch_size = 10000\n",
    "        \n",
    "        try:\n",
    "            for offset in range(0, total_count, batch_size):\n",
    "                last_idx = min(offset + batch_size, total_count)\n",
    "                print(f\"Fetching {offset} to {last_idx} of {total_count}\")\n",
    "                data = self.data_source.data(query, limit=batch_size, offset=offset)\n",
    "                all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying data: {e}\")\n",
    "\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98876a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataInspector:\n",
    "    def display(self, data, columns):\n",
    "        styled_df = data[[col.lower() for col in columns]].head().style.set_table_styles([{\n",
    "            'selector': 'table',\n",
    "            'props': [('max-width', '1000px'), ('overflow-x', 'scroll'), ('display', 'block')]\n",
    "        }])\n",
    "\n",
    "        display(styled_df)\n",
    "        print(f\"Total count: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9dd6a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3:\n",
    "    def __init__(self, bucket_name):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.s3 = boto3.client('s3')\n",
    "        \n",
    "    def save_model(self, model, name):\n",
    "        model_buffer = io.BytesIO()\n",
    "        joblib.dump(model, model_buffer)\n",
    "        model_buffer.seek(0)\n",
    "        try:\n",
    "            file_key = f\"models/{name}.joblib\"\n",
    "            self.s3.upload_fileobj(model_buffer, self.bucket_name, file_key)\n",
    "            print(f\"Model successfully uploaded to s3://{self.bucket_name}/{file_key}\")\n",
    "            return f\"s3://{self.bucket_name}/{file_key}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to upload model to S3: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81253035",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def transformed_data(self):\n",
    "        self.transform()\n",
    "        return self.data\n",
    "    \n",
    "    def transform(self):\n",
    "        self.encode_categorical()\n",
    "        self.add_new_features()\n",
    "        \n",
    "    def encode_categorical(self):\n",
    "        le = LabelEncoder()\n",
    "        categorical_columns = ['livingsituation', 'livingsituationgrouping', 'destination', 'destinationgrouping']\n",
    "        for col in categorical_columns:\n",
    "            self.data[col] = le.fit_transform(self.data[col])\n",
    "            \n",
    "    def add_new_features(self):\n",
    "        # create a feature for enrollment duration in days\n",
    "        self.data['entrydate'] = pd.to_datetime(self.data['entrydate'])\n",
    "        self.data['exitdate'] = pd.to_datetime(self.data['exitdate'])\n",
    "        self.data['enrollment_duration'] = (self.data['exitdate'] - self.data['entrydate']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf3be593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, random_state=413):\n",
    "        self.random_state = random_state\n",
    "        self.data = data\n",
    "        self.train_test_split()\n",
    "        \n",
    "    def train_test_split(self):\n",
    "        # create an 80/10/10 train/val/test split\n",
    "        self.X_train, X_temp, self.y_train, y_temp = train_test_split(\n",
    "            self.X(), self.y(), test_size=0.2, random_state=self.random_state\n",
    "        )\n",
    "        self.X_val, self.X_test, self.y_val, self.y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "    def X(self):\n",
    "        return self.data[['livingsituation', 'livingsituationgrouping', 'enrollment_duration']]\n",
    "    \n",
    "    def y(self):\n",
    "        return self.data['destinationgrouping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d4cf5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel:\n",
    "    def __init__(self, random_state=413):\n",
    "        self.model = RandomForestClassifier(random_state=random_state)\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "be1cd349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    def run(self):\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        data_source = DataSource(self.db_config())\n",
    "        s3 = S3(bucket_name='capstone-hmis')\n",
    "\n",
    "        print(\"Querying RDS for data...\")\n",
    "        data_retriever = DataRetriever(data_source)\n",
    "        data = data_retriever.records()\n",
    "\n",
    "        print(\"Data before feature engineering\")\n",
    "        data_inspector = DataInspector()\n",
    "        data_inspector.display(data, data.columns.tolist())\n",
    "\n",
    "        feature_engineer = FeatureEngineer(data)\n",
    "        transformed_data = feature_engineer.transformed_data()\n",
    "        print(\"Data after feature engineering\")\n",
    "        data_inspector.display(transformed_data, transformed_data.columns.tolist())\n",
    "        \n",
    "        dataset = Dataset(transformed_data)\n",
    "\n",
    "        print(\"\\nFitting Baseline Model...\")\n",
    "        model = BaselineModel()\n",
    "        model.fit(dataset.X_train, dataset.y_train)\n",
    "        \n",
    "        # TODO: implement train/val loop here\n",
    "        \n",
    "        print(\"Test Baseline Model\")\n",
    "        y_pred = model.predict(dataset.X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(dataset.y_test, y_pred)\n",
    "        # 'weighted': F1 score for multi-class classification by taking the weighted average of F1 scores for each class, considering the class imbalance.\n",
    "        # 'macro': Unweighted mean of F1 scores for each label.\n",
    "        # 'micro': Aggregate the contributions of all classes to compute the F1 score.\n",
    "        # 'binary': Default for binary classification.\n",
    "        f1 = f1_score(dataset.y_test, y_pred, average='weighted')\n",
    "        print(\"\\n====================================================================\\n\")\n",
    "        print(f\" BaselineModel(RandomForestClassifier) Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "        print(\"\\n====================================================================\\n\")\n",
    "\n",
    "        print(\"Saving model to S3...\")\n",
    "        s3_model_location = s3.save_model(\n",
    "            model=model.model,\n",
    "            name=f\"baseline-v1-{datetime.now():%Y-%m-%d}\"\n",
    "        )\n",
    "        \n",
    "        print(\"Logging experiment in RDS experiments table\")\n",
    "        data_source.log_experiment(\n",
    "            model_type='RandomForest',\n",
    "            hyperparameters=model.model.get_params(),\n",
    "            training_data_version='v0.0.1',\n",
    "            performance_metrics={\"accuracy\": accuracy, \"f1_score\": f1},\n",
    "            s3_model_location=s3_model_location,\n",
    "            start_time=start_time,\n",
    "            end_time=datetime.now(),\n",
    "            status='Completed',\n",
    "            notes='First Baseline RandomForest model experiment'\n",
    "        )\n",
    "        \n",
    "        print(\"Experiment Complete!\")\n",
    "    \n",
    "    def db_config(self):\n",
    "        return SimpleNamespace(\n",
    "            host=\"capstone-database.cr62wyo4a7dt.us-east-2.rds.amazonaws.com\",\n",
    "            database=\"capstone\",\n",
    "            user=\"postgres\",\n",
    "            password=\"<PASSWORD_HERE_2>\",\n",
    "            port=\"5432\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bd64a809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to RDS successful\n",
      "Querying RDS for data...\n",
      "Fetching 0 to 10000 of 443437\n",
      "Fetching 10000 to 20000 of 443437\n",
      "Fetching 20000 to 30000 of 443437\n",
      "Fetching 30000 to 40000 of 443437\n",
      "Fetching 40000 to 50000 of 443437\n",
      "Fetching 50000 to 60000 of 443437\n",
      "Fetching 60000 to 70000 of 443437\n",
      "Fetching 70000 to 80000 of 443437\n",
      "Fetching 80000 to 90000 of 443437\n",
      "Fetching 90000 to 100000 of 443437\n",
      "Fetching 100000 to 110000 of 443437\n",
      "Fetching 110000 to 120000 of 443437\n",
      "Fetching 120000 to 130000 of 443437\n",
      "Fetching 130000 to 140000 of 443437\n",
      "Fetching 140000 to 150000 of 443437\n",
      "Fetching 150000 to 160000 of 443437\n",
      "Fetching 160000 to 170000 of 443437\n",
      "Fetching 170000 to 180000 of 443437\n",
      "Fetching 180000 to 190000 of 443437\n",
      "Fetching 190000 to 200000 of 443437\n",
      "Fetching 200000 to 210000 of 443437\n",
      "Fetching 210000 to 220000 of 443437\n",
      "Fetching 220000 to 230000 of 443437\n",
      "Fetching 230000 to 240000 of 443437\n",
      "Fetching 240000 to 250000 of 443437\n",
      "Fetching 250000 to 260000 of 443437\n",
      "Fetching 260000 to 270000 of 443437\n",
      "Fetching 270000 to 280000 of 443437\n",
      "Fetching 280000 to 290000 of 443437\n",
      "Fetching 290000 to 300000 of 443437\n",
      "Fetching 300000 to 310000 of 443437\n",
      "Fetching 310000 to 320000 of 443437\n",
      "Fetching 320000 to 330000 of 443437\n",
      "Fetching 330000 to 340000 of 443437\n",
      "Fetching 340000 to 350000 of 443437\n",
      "Fetching 350000 to 360000 of 443437\n",
      "Fetching 360000 to 370000 of 443437\n",
      "Fetching 370000 to 380000 of 443437\n",
      "Fetching 380000 to 390000 of 443437\n",
      "Fetching 390000 to 400000 of 443437\n",
      "Fetching 400000 to 410000 of 443437\n",
      "Fetching 410000 to 420000 of 443437\n",
      "Fetching 420000 to 430000 of 443437\n",
      "Fetching 430000 to 440000 of 443437\n",
      "Fetching 440000 to 443437 of 443437\n",
      "Data before feature engineering\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0808a table {\n",
       "  max-width: 1000px;\n",
       "  overflow-x: scroll;\n",
       "  display: block;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0808a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0808a_level0_col0\" class=\"col_heading level0 col0\" >enrollmentid</th>\n",
       "      <th id=\"T_0808a_level0_col1\" class=\"col_heading level0 col1\" >personalid</th>\n",
       "      <th id=\"T_0808a_level0_col2\" class=\"col_heading level0 col2\" >projectid</th>\n",
       "      <th id=\"T_0808a_level0_col3\" class=\"col_heading level0 col3\" >entrydate</th>\n",
       "      <th id=\"T_0808a_level0_col4\" class=\"col_heading level0 col4\" >dateofengagement</th>\n",
       "      <th id=\"T_0808a_level0_col5\" class=\"col_heading level0 col5\" >livingsituation</th>\n",
       "      <th id=\"T_0808a_level0_col6\" class=\"col_heading level0 col6\" >livingsituationgrouping</th>\n",
       "      <th id=\"T_0808a_level0_col7\" class=\"col_heading level0 col7\" >exitid</th>\n",
       "      <th id=\"T_0808a_level0_col8\" class=\"col_heading level0 col8\" >exitdate</th>\n",
       "      <th id=\"T_0808a_level0_col9\" class=\"col_heading level0 col9\" >destination</th>\n",
       "      <th id=\"T_0808a_level0_col10\" class=\"col_heading level0 col10\" >destinationgrouping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0808a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0808a_row0_col0\" class=\"data row0 col0\" >LA|109821</td>\n",
       "      <td id=\"T_0808a_row0_col1\" class=\"data row0 col1\" >LA|138263</td>\n",
       "      <td id=\"T_0808a_row0_col2\" class=\"data row0 col2\" >LA|1216</td>\n",
       "      <td id=\"T_0808a_row0_col3\" class=\"data row0 col3\" >2013-01-15</td>\n",
       "      <td id=\"T_0808a_row0_col4\" class=\"data row0 col4\" >None</td>\n",
       "      <td id=\"T_0808a_row0_col5\" class=\"data row0 col5\" >Rental by client, no subsidy</td>\n",
       "      <td id=\"T_0808a_row0_col6\" class=\"data row0 col6\" >Permanent Housing Situation</td>\n",
       "      <td id=\"T_0808a_row0_col7\" class=\"data row0 col7\" >LA|351405</td>\n",
       "      <td id=\"T_0808a_row0_col8\" class=\"data row0 col8\" >2013-01-30</td>\n",
       "      <td id=\"T_0808a_row0_col9\" class=\"data row0 col9\" >312</td>\n",
       "      <td id=\"T_0808a_row0_col10\" class=\"data row0 col10\" >Temporary Situation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0808a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0808a_row1_col0\" class=\"data row1 col0\" >LA|130721</td>\n",
       "      <td id=\"T_0808a_row1_col1\" class=\"data row1 col1\" >LA|138505</td>\n",
       "      <td id=\"T_0808a_row1_col2\" class=\"data row1 col2\" >LA|1218</td>\n",
       "      <td id=\"T_0808a_row1_col3\" class=\"data row1 col3\" >2013-01-22</td>\n",
       "      <td id=\"T_0808a_row1_col4\" class=\"data row1 col4\" >None</td>\n",
       "      <td id=\"T_0808a_row1_col5\" class=\"data row1 col5\" >Rental by client, no subsidy</td>\n",
       "      <td id=\"T_0808a_row1_col6\" class=\"data row1 col6\" >Permanent Housing Situation</td>\n",
       "      <td id=\"T_0808a_row1_col7\" class=\"data row1 col7\" >LA|352266</td>\n",
       "      <td id=\"T_0808a_row1_col8\" class=\"data row1 col8\" >2013-02-01</td>\n",
       "      <td id=\"T_0808a_row1_col9\" class=\"data row1 col9\" >314</td>\n",
       "      <td id=\"T_0808a_row1_col10\" class=\"data row1 col10\" >Temporary Situation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0808a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0808a_row2_col0\" class=\"data row2 col0\" >LA|256780</td>\n",
       "      <td id=\"T_0808a_row2_col1\" class=\"data row2 col1\" >LA|138508</td>\n",
       "      <td id=\"T_0808a_row2_col2\" class=\"data row2 col2\" >LA|1218</td>\n",
       "      <td id=\"T_0808a_row2_col3\" class=\"data row2 col3\" >2013-01-22</td>\n",
       "      <td id=\"T_0808a_row2_col4\" class=\"data row2 col4\" >None</td>\n",
       "      <td id=\"T_0808a_row2_col5\" class=\"data row2 col5\" >Rental by client, no subsidy</td>\n",
       "      <td id=\"T_0808a_row2_col6\" class=\"data row2 col6\" >Permanent Housing Situation</td>\n",
       "      <td id=\"T_0808a_row2_col7\" class=\"data row2 col7\" >LA|352270</td>\n",
       "      <td id=\"T_0808a_row2_col8\" class=\"data row2 col8\" >2013-02-01</td>\n",
       "      <td id=\"T_0808a_row2_col9\" class=\"data row2 col9\" >314</td>\n",
       "      <td id=\"T_0808a_row2_col10\" class=\"data row2 col10\" >Temporary Situation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0808a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0808a_row3_col0\" class=\"data row3 col0\" >LA|62884</td>\n",
       "      <td id=\"T_0808a_row3_col1\" class=\"data row3 col1\" >LA|138518</td>\n",
       "      <td id=\"T_0808a_row3_col2\" class=\"data row3 col2\" >LA|1218</td>\n",
       "      <td id=\"T_0808a_row3_col3\" class=\"data row3 col3\" >2013-01-23</td>\n",
       "      <td id=\"T_0808a_row3_col4\" class=\"data row3 col4\" >None</td>\n",
       "      <td id=\"T_0808a_row3_col5\" class=\"data row3 col5\" >Staying/ living in friends house</td>\n",
       "      <td id=\"T_0808a_row3_col6\" class=\"data row3 col6\" >Temporary Situation</td>\n",
       "      <td id=\"T_0808a_row3_col7\" class=\"data row3 col7\" >LA|352289</td>\n",
       "      <td id=\"T_0808a_row3_col8\" class=\"data row3 col8\" >2013-02-13</td>\n",
       "      <td id=\"T_0808a_row3_col9\" class=\"data row3 col9\" >101</td>\n",
       "      <td id=\"T_0808a_row3_col10\" class=\"data row3 col10\" >Homeless Situation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0808a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0808a_row4_col0\" class=\"data row4 col0\" >LA|224292</td>\n",
       "      <td id=\"T_0808a_row4_col1\" class=\"data row4 col1\" >LA|139019</td>\n",
       "      <td id=\"T_0808a_row4_col2\" class=\"data row4 col2\" >LA|1218</td>\n",
       "      <td id=\"T_0808a_row4_col3\" class=\"data row4 col3\" >2013-01-24</td>\n",
       "      <td id=\"T_0808a_row4_col4\" class=\"data row4 col4\" >None</td>\n",
       "      <td id=\"T_0808a_row4_col5\" class=\"data row4 col5\" >Staying/ living in families house</td>\n",
       "      <td id=\"T_0808a_row4_col6\" class=\"data row4 col6\" >Temporary Situation</td>\n",
       "      <td id=\"T_0808a_row4_col7\" class=\"data row4 col7\" >LA|353651</td>\n",
       "      <td id=\"T_0808a_row4_col8\" class=\"data row4 col8\" >2013-02-15</td>\n",
       "      <td id=\"T_0808a_row4_col9\" class=\"data row4 col9\" >101</td>\n",
       "      <td id=\"T_0808a_row4_col10\" class=\"data row4 col10\" >Homeless Situation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f74ae683c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 443437\n",
      "Data after feature engineering\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_73447 table {\n",
       "  max-width: 1000px;\n",
       "  overflow-x: scroll;\n",
       "  display: block;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_73447\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_73447_level0_col0\" class=\"col_heading level0 col0\" >enrollmentid</th>\n",
       "      <th id=\"T_73447_level0_col1\" class=\"col_heading level0 col1\" >personalid</th>\n",
       "      <th id=\"T_73447_level0_col2\" class=\"col_heading level0 col2\" >projectid</th>\n",
       "      <th id=\"T_73447_level0_col3\" class=\"col_heading level0 col3\" >entrydate</th>\n",
       "      <th id=\"T_73447_level0_col4\" class=\"col_heading level0 col4\" >dateofengagement</th>\n",
       "      <th id=\"T_73447_level0_col5\" class=\"col_heading level0 col5\" >livingsituation</th>\n",
       "      <th id=\"T_73447_level0_col6\" class=\"col_heading level0 col6\" >livingsituationgrouping</th>\n",
       "      <th id=\"T_73447_level0_col7\" class=\"col_heading level0 col7\" >exitid</th>\n",
       "      <th id=\"T_73447_level0_col8\" class=\"col_heading level0 col8\" >exitdate</th>\n",
       "      <th id=\"T_73447_level0_col9\" class=\"col_heading level0 col9\" >destination</th>\n",
       "      <th id=\"T_73447_level0_col10\" class=\"col_heading level0 col10\" >destinationgrouping</th>\n",
       "      <th id=\"T_73447_level0_col11\" class=\"col_heading level0 col11\" >enrollment_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_73447_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_73447_row0_col0\" class=\"data row0 col0\" >LA|109821</td>\n",
       "      <td id=\"T_73447_row0_col1\" class=\"data row0 col1\" >LA|138263</td>\n",
       "      <td id=\"T_73447_row0_col2\" class=\"data row0 col2\" >LA|1216</td>\n",
       "      <td id=\"T_73447_row0_col3\" class=\"data row0 col3\" >2013-01-15 00:00:00</td>\n",
       "      <td id=\"T_73447_row0_col4\" class=\"data row0 col4\" >None</td>\n",
       "      <td id=\"T_73447_row0_col5\" class=\"data row0 col5\" >15</td>\n",
       "      <td id=\"T_73447_row0_col6\" class=\"data row0 col6\" >3</td>\n",
       "      <td id=\"T_73447_row0_col7\" class=\"data row0 col7\" >LA|351405</td>\n",
       "      <td id=\"T_73447_row0_col8\" class=\"data row0 col8\" >2013-01-30 00:00:00</td>\n",
       "      <td id=\"T_73447_row0_col9\" class=\"data row0 col9\" >16</td>\n",
       "      <td id=\"T_73447_row0_col10\" class=\"data row0 col10\" >4</td>\n",
       "      <td id=\"T_73447_row0_col11\" class=\"data row0 col11\" >15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_73447_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_73447_row1_col0\" class=\"data row1 col0\" >LA|130721</td>\n",
       "      <td id=\"T_73447_row1_col1\" class=\"data row1 col1\" >LA|138505</td>\n",
       "      <td id=\"T_73447_row1_col2\" class=\"data row1 col2\" >LA|1218</td>\n",
       "      <td id=\"T_73447_row1_col3\" class=\"data row1 col3\" >2013-01-22 00:00:00</td>\n",
       "      <td id=\"T_73447_row1_col4\" class=\"data row1 col4\" >None</td>\n",
       "      <td id=\"T_73447_row1_col5\" class=\"data row1 col5\" >15</td>\n",
       "      <td id=\"T_73447_row1_col6\" class=\"data row1 col6\" >3</td>\n",
       "      <td id=\"T_73447_row1_col7\" class=\"data row1 col7\" >LA|352266</td>\n",
       "      <td id=\"T_73447_row1_col8\" class=\"data row1 col8\" >2013-02-01 00:00:00</td>\n",
       "      <td id=\"T_73447_row1_col9\" class=\"data row1 col9\" >18</td>\n",
       "      <td id=\"T_73447_row1_col10\" class=\"data row1 col10\" >4</td>\n",
       "      <td id=\"T_73447_row1_col11\" class=\"data row1 col11\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_73447_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_73447_row2_col0\" class=\"data row2 col0\" >LA|256780</td>\n",
       "      <td id=\"T_73447_row2_col1\" class=\"data row2 col1\" >LA|138508</td>\n",
       "      <td id=\"T_73447_row2_col2\" class=\"data row2 col2\" >LA|1218</td>\n",
       "      <td id=\"T_73447_row2_col3\" class=\"data row2 col3\" >2013-01-22 00:00:00</td>\n",
       "      <td id=\"T_73447_row2_col4\" class=\"data row2 col4\" >None</td>\n",
       "      <td id=\"T_73447_row2_col5\" class=\"data row2 col5\" >15</td>\n",
       "      <td id=\"T_73447_row2_col6\" class=\"data row2 col6\" >3</td>\n",
       "      <td id=\"T_73447_row2_col7\" class=\"data row2 col7\" >LA|352270</td>\n",
       "      <td id=\"T_73447_row2_col8\" class=\"data row2 col8\" >2013-02-01 00:00:00</td>\n",
       "      <td id=\"T_73447_row2_col9\" class=\"data row2 col9\" >18</td>\n",
       "      <td id=\"T_73447_row2_col10\" class=\"data row2 col10\" >4</td>\n",
       "      <td id=\"T_73447_row2_col11\" class=\"data row2 col11\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_73447_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_73447_row3_col0\" class=\"data row3 col0\" >LA|62884</td>\n",
       "      <td id=\"T_73447_row3_col1\" class=\"data row3 col1\" >LA|138518</td>\n",
       "      <td id=\"T_73447_row3_col2\" class=\"data row3 col2\" >LA|1218</td>\n",
       "      <td id=\"T_73447_row3_col3\" class=\"data row3 col3\" >2013-01-23 00:00:00</td>\n",
       "      <td id=\"T_73447_row3_col4\" class=\"data row3 col4\" >None</td>\n",
       "      <td id=\"T_73447_row3_col5\" class=\"data row3 col5\" >19</td>\n",
       "      <td id=\"T_73447_row3_col6\" class=\"data row3 col6\" >4</td>\n",
       "      <td id=\"T_73447_row3_col7\" class=\"data row3 col7\" >LA|352289</td>\n",
       "      <td id=\"T_73447_row3_col8\" class=\"data row3 col8\" >2013-02-13 00:00:00</td>\n",
       "      <td id=\"T_73447_row3_col9\" class=\"data row3 col9\" >6</td>\n",
       "      <td id=\"T_73447_row3_col10\" class=\"data row3 col10\" >0</td>\n",
       "      <td id=\"T_73447_row3_col11\" class=\"data row3 col11\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_73447_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_73447_row4_col0\" class=\"data row4 col0\" >LA|224292</td>\n",
       "      <td id=\"T_73447_row4_col1\" class=\"data row4 col1\" >LA|139019</td>\n",
       "      <td id=\"T_73447_row4_col2\" class=\"data row4 col2\" >LA|1218</td>\n",
       "      <td id=\"T_73447_row4_col3\" class=\"data row4 col3\" >2013-01-24 00:00:00</td>\n",
       "      <td id=\"T_73447_row4_col4\" class=\"data row4 col4\" >None</td>\n",
       "      <td id=\"T_73447_row4_col5\" class=\"data row4 col5\" >18</td>\n",
       "      <td id=\"T_73447_row4_col6\" class=\"data row4 col6\" >4</td>\n",
       "      <td id=\"T_73447_row4_col7\" class=\"data row4 col7\" >LA|353651</td>\n",
       "      <td id=\"T_73447_row4_col8\" class=\"data row4 col8\" >2013-02-15 00:00:00</td>\n",
       "      <td id=\"T_73447_row4_col9\" class=\"data row4 col9\" >6</td>\n",
       "      <td id=\"T_73447_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_73447_row4_col11\" class=\"data row4 col11\" >22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f74ad4088b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 443437\n",
      "\n",
      "Fitting Baseline Model...\n",
      "Test Baseline Model\n",
      "\n",
      "====================================================================\n",
      "\n",
      " BaselineModel(RandomForestClassifier) Accuracy: 0.7284, F1: 0.6484\n",
      "\n",
      "====================================================================\n",
      "\n",
      "Saving model to S3...\n",
      "Model successfully uploaded to s3://capstone-hmis/models/baseline-v1-2024-10-08.joblib\n",
      "Logging experiment in RDS experiments table\n",
      "Experiment Complete!\n"
     ]
    }
   ],
   "source": [
    "pipeline = DataPipeline()\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a3499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
